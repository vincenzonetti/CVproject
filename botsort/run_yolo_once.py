import cv2
import numpy as np
from ultralytics import YOLO
import json
import os

model = YOLO("yolo11s_ft.pt") # Or your custom model path
video_name = 'out13'
video_path = f"../data/videos/{video_name}.mp4"
output_path = f"../data/output/{video_name}_yolo_kalman_ball.mp4" # Output path for the final video
storage_dir = '../data/processed_frames_all_detections' # Directory to store annotated frames and all detection data

# Ensure storage directory exists
if not os.path.exists(storage_dir):
    os.makedirs(storage_dir)

# Data structure to store all detection info
# Dictionary where keys are frame indices (as strings)
# Values are lists of dictionaries, each representing a detection
all_detections_data = {}

cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

# ... (get video properties - optional for saving, but useful later) ...

frame_idx = 0
print(f"Processing video frames and detecting all objects for storage in {storage_dir}...")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    if frame is None:
        print(f"Warning: Received None frame at index {frame_idx}")
        frame_idx += 1
        continue

    # Run YOLO model with tracking
    # The 'track' method provides 'id' attribute in boxes if tracking is successful
    yolo_results = model.track(frame, persist=True, line_width=1, tracker="botsort.yaml", verbose=False)

    frame_detections = [] # List to store detections for the current frame

    if yolo_results and yolo_results[0].boxes is not None and len(yolo_results[0].boxes.xyxy) > 0:
        boxes = yolo_results[0].boxes
        # Iterate through all detections in the current frame
        for i in range(len(boxes)):
            box = boxes.xyxy[i].cpu().numpy().tolist() # Bbox as [x1, y1, x2, y2]
            conf = float(boxes.conf[i].cpu().numpy())
            cls = int(boxes.cls[i].cpu().numpy())
            # Check if tracking ID exists (only if tracking was successful for this box)
            track_id = int(boxes.id[i].cpu().numpy()) if boxes.id is not None and i < len(boxes.id) and boxes.id[i] is not None else -1 # Use -1 if no track ID

            frame_detections.append({
                'box': box,
                'confidence': conf,
                'class_id': cls,
                'track_id': track_id
            })

        # Store detections for this frame
        all_detections_data[str(frame_idx)] = frame_detections

        # Optionally, save the annotated frame image generated by YOLO
        # If you save the raw data, you might choose NOT to save this if you
        # prefer to draw everything from scratch during loading.
        # However, saving it can speed up the final video generation if the
        # default YOLO plotting is sufficient.
    else:
         # If no detections but you still want to save a blank/original frame
         # and have an entry in the data file for this frame index
         # If you saved the annotated frame image even without detections, this is covered.
         # If not saving annotated images, you might still add an empty list entry:
         # all_detections_data[str(frame_idx)] = []

         # If not saving annotated images, you would get the raw frame to save
         # frame_filename = os.path.join(storage_dir, f"frame_{frame_idx:05d}.png")
         # cv2.imwrite(frame_filename, frame) # Save original frame

         # If you saved the annotated image regardless of detections, this is done above.
         # Ensure the frame index is in the data dictionary even with no detections
         if str(frame_idx) not in all_detections_data:
              all_detections_data[str(frame_idx)] = []


    frame_idx += 1

cap.release()

# Save the all detections data to a JSON file
detections_filepath = os.path.join(storage_dir, f"{video_name}_all_detections.json")
with open(detections_filepath, 'w') as f:
    json.dump(all_detections_data, f, indent=4) # Use indent for readability

print(f"Finished processing video. Annotated frames saved to {storage_dir} (if enabled) and all detection data to {detections_filepath}.")
